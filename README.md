# Credit_Risk_Analysis
## MODULE 17 SUPERVISED MACHINE LEARNING

### OVERVIEW
You are assisting Jill, the lead Data Scientist at FAST LENDING a lending services company whose management wants to use machine learning to predict credit risk as they believe this will provide a quicker and more reliable loan experience by more accurately identifying good candidates for loans which in turn will lead to lower default rates.  This will be accomplished by using several different Machine Learning models, algorithms and techniques.

### NEW TOOLS
* Scikit-learn LIBRARY

### LIST OF MACHINE LEARNING MODELS
* LOGISTIC REGRESSION
* SUPPORT VECTOR MACHINES
* DECISION TREE MODEL
* RANDOM FOREST MODEL

### ML TECHNIQUES:
* F1 SCORE (aka HARMONIC MEAN) = 2 (PRECISION * SENSITIVITY) / (PRECISION + SENSITIVITY)
* PRECISION (aka POSITIVE PREDICTIVE VALUE) = TRUE POSITIVE/(TRUE POSITIVE + FALSE POSITIVE)
* SENSITIVITY (aka RECALL) = TRUE POSITIVE/(TRUE POSITIVE + FALSE NEGATIVE)
* BOOTSTRAP AGGREGATION (aka BAGGING)
* BOOSTING (ADAPTIVE and GRADIENT)
* RANDOM OVERSAMPLING
* SYNTHETIC MINORITY OVERSAMPLING TECHNIQUE (aka SMOTE)
* RANDOM UNDERSAMPLING
* SMOTEENN (SMOTE + EDITED NEAREST NEIGHBORS algorithmn)

### RESULTS
#### NAIVE RANDOM OVERSAMPLING
* BALANCED ACCURACY SCORE: 0.6413263312262552
* CONFUSION MATRIX:
![MOD17 CHALLENGE - OVERSAMPLE 4) CONFUSION MATRIX](https://user-images.githubusercontent.com/99851509/178199213-3cca1628-8609-46a0-b6a8-8f6d1f8dec57.png)
* CLASSIFICATION REPORT:
![MOD17 CHALLENGE - OVERSAMPLE 5) CLASSIFICATION REPORT](https://user-images.githubusercontent.com/99851509/178199318-764fcd23-1d12-47da-bc9e-7b69c13913ef.png)


#### SMOTE OVERSAMPLING
* SMOTE BALANCED ACCURACY SCORE: 0.5293318990697431
* SMOTE CONFUSION MATRIX
![MOD17 CHALLENGE - SMOTE 4) CONFUSION MATRIX](https://user-images.githubusercontent.com/99851509/178199824-4e44b907-b043-4629-99bb-8d7c413df3c6.png)
* SMOTE CLASSIFICATION REPORT
![MOD17 CHALLENGE - SMOTE 5) CLASSIFICATION REPORT](https://user-images.githubusercontent.com/99851509/178200111-80d6fe07-93e0-406c-b7dd-417412d0ce12.png)


#### UNDERSAMPLING
* UNDERSAMPLING BALANCED ACCURACY SCORE: 0.5292734810302525
* UNDERSAMPLING CONFUSION MATRIX
![MOD17 CHALLENGE - UNDERSAMPLE 4) CONFUSION MATRIX](https://user-images.githubusercontent.com/99851509/178200657-829f79b5-fffa-4042-965f-9b0ba8a1bebd.png)
* UNDERSAMPLING CLASSIFICATION REPORT
![MOD17 CHALLENGE - UNDERSAMPLE 5) CLASSIFICATION REPORT](https://user-images.githubusercontent.com/99851509/178200741-08926924-eedc-4208-a2d4-0ed0ccd8510a.png)


#### COMBINATION (SMOTEENN)
* SMOTEENN BALANCED ACCURACY SCORE: 0.6393350818456878
* SMOTEENN CONFUSION MATRIX
![MOD17 CHALLENGE - COMBO 4) CONFUSION MATRIX](https://user-images.githubusercontent.com/99851509/178201022-6468b4bf-374b-418d-a533-67fefbcb50b2.png)
* SMOTEENN CLASSIFICATION REPORT
![MOD17 CHALLENGE - COMBO 5) CLASSIFICATION REPORT](https://user-images.githubusercontent.com/99851509/178201103-8bb5261e-2020-4c58-b32d-2ce4cba7a551.png)


#### BALANCED RANDOM FOREST
* RANDOM FOREST BALANCED ACCURACY SCORE: 0.7885466545953005
* RANDOM FOREST CONFUSION MATRIX
![MOD17 CHALLENGE DEL III - BRFC 4) CONFUSION MATRIX](https://user-images.githubusercontent.com/99851509/178201631-e8fa6b15-7856-4ce0-b503-83afac663fdd.png)
* RANDOM FOREST CLASSIFICATION REPORT
![MOD17 CHALLENGE DEL III - BRFC 5) CLASSIFICATION REPORT](https://user-images.githubusercontent.com/99851509/178201701-3f9d3ba8-0936-4838-932c-8eb26f7fa1ce.png)


#### EASY ENSEMBLE 
* EASY ENSEMBLE BALANCED ACCURACY SCORE: 0.9316600714093861
* EASY ENSEMBLE CONFUSION MATRIX
![MOD17 CHALLENGE DEL III - EEC CONFUSION MATRIX](https://user-images.githubusercontent.com/99851509/178202009-3436f4d1-8595-4531-8e84-90c8e2111389.png)
* EASY ENSEMBLE CLASSIFICATION REPORT
![MOD17 CHALLENGE DEL III - EEC CLASSIFICATION REPORT](https://user-images.githubusercontent.com/99851509/178202094-c147a19e-ce2c-47bc-b15a-a8868e1717a4.png)


### SUMMARY
Of the 6 Machine Learning models in the Challenge, the BALANCED ACCURACY SCORE for the EASY ENSEMBLE CLASSIFIER was the highest with a 93% score.  It also showed a PRECISION of 9% and an F1 SCORE of 16% which would make the it a riskier choice.  The BALANCED RANDOM FOREST model also scored well with a percentile of 78.9%, but the PRECISION was lower at 3% compared to the EASY ENSEMBLE CLASSIFIER model.  The other models scored 64% or lower making them not as accurate.  As a result, I would recommend the EASY ENSEMBLE CLASSIFIER model out of these 6.  I could not recommend another model altogether without seeing the results.
